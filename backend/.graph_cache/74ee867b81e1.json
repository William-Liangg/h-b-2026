{"files": ["README.md", "deepchrome_doall.py", "featmap.py", "ml_doall.py", "old_scripts/[deprecated]_optim_v0.py", "old_scripts/[deprecated]_optim_v1.py", "old_scripts/[deprecated]_optim_v2.py", "old_scripts/[deprecated]_optim_v3.py", "old_scripts/[deprecated]_patch_v0.py", "old_scripts/[deprecated]_patch_v1.py", "old_scripts/[deprecated]_patch_v2.py", "old_scripts/[deprecated]_patchnll_v0.py", "optim.py"], "edges": [], "root": "/Users/nicolaskim/Desktop/learning/_hackathons/tmp/h-b-2026/backend/.repos/74ee867b81e1", "file_analyses": {"README.md": {"importance_score": 8, "summary": "Main project documentation describing a DeepChrome model reimplementation for predicting gene expression from histone modifications.", "responsibilities": ["Document project structure and scripts", "Explain subfolder organization", "Provide overview of implemented models and analyses", "Guide users to results and benchmarks"], "key_exports": [], "onboarding_reason": "New developers should read this first to understand the project's purpose, available scripts, and how the codebase is organized."}, "deepchrome_doall.py": {"importance_score": 9, "summary": "Main entry point script that runs complete DeepChrome model training, evaluation, and generates performance metrics.", "responsibilities": ["Orchestrate full model pipeline from training to evaluation", "Handle data loading and preprocessing with custom Dataset/BatchSampler", "Define and train ConvNet architecture", "Generate AUC, loss scores and save results"], "key_exports": ["run_all", "HistoneDataset", "BSampler"], "onboarding_reason": "This is the primary script new developers should understand as it contains the core DeepChrome implementation and training pipeline."}, "featmap.py": {"importance_score": 7, "summary": "Script for generating combinatorial interaction heatmaps and feature analysis from trained DeepChrome models.", "responsibilities": ["Extract convolutional layer features from trained models", "Generate feature map visualizations across cell types", "Load and process data for multiple cell types", "Create heatmap plots of feature distributions"], "key_exports": ["set_device", "load_data", "ConvNet", "extract_features", "plot_feat_map"], "onboarding_reason": "Important for understanding model interpretability and how to analyze what the trained models have learned."}, "ml_doall.py": {"importance_score": 7, "summary": "Baseline machine learning models script implementing Random Forest, SVM, and XGBoost for comparison with DeepChrome.", "responsibilities": ["Implement baseline ML models for performance comparison", "Use same data preprocessing pipeline as DeepChrome", "Train and evaluate traditional ML approaches", "Provide benchmarking against deep learning model"], "key_exports": ["run_all", "HistoneDataset", "BSampler"], "onboarding_reason": "Essential for understanding baseline comparisons and how traditional ML approaches perform on the same data."}, "old_scripts/[deprecated]_optim_v0.py": {"importance_score": 2, "summary": "Deprecated optimization script for input optimization following the procedure specified in the paper.", "responsibilities": ["Load data and create tensor representations", "Implement model optimization procedures", "Set hyperparameters for different configurations", "Perform gradient-based input optimization"], "key_exports": ["set_device", "load_data", "set_hyperparams", "ConvNet", "opt"], "onboarding_reason": "This is deprecated code that new developers can skip unless they need to understand the evolution of the optimization approach."}, "old_scripts/[deprecated]_optim_v1.py": {"importance_score": 1, "summary": "Another deprecated version of optimization script with simplified approach for input optimization.", "responsibilities": ["Load data and calculate class weights", "Define ConvNet architecture", "Implement gradient-based optimization loop", "Process optimization results"], "key_exports": ["load_data", "set_device", "ConvNet", "opt", "loop"], "onboarding_reason": "Deprecated code that can be ignored by new developers."}, "old_scripts/[deprecated]_optim_v2.py": {"importance_score": 1, "summary": "Deprecated optimization script with class-based data organization for input optimization.", "responsibilities": ["Separate data by expression classes", "Load and organize data by gene expression levels", "Set up optimization framework", "Define model architecture"], "key_exports": ["set_device", "load_data", "set_hyperparams", "ConvNet", "opt"], "onboarding_reason": "Deprecated code that new developers should skip."}, "old_scripts/[deprecated]_optim_v3.py": {"importance_score": 1, "summary": "Deprecated optimization script with modified ConvNet architecture (no dropout in forward pass).", "responsibilities": ["Load and organize data by expression classes", "Define modified ConvNet without dropout", "Set up optimization parameters", "Prepare for gradient-based optimization"], "key_exports": ["set_device", "load_data", "set_hyperparams", "ConvNet", "opt"], "onboarding_reason": "Deprecated code that can be ignored."}, "old_scripts/[deprecated]_patch_v0.py": {"importance_score": 1, "summary": "Deprecated version of the main DeepChrome script with similar functionality to deepchrome_doall.py.", "responsibilities": ["Implement DeepChrome training pipeline", "Handle data loading and preprocessing", "Define custom Dataset and BatchSampler classes", "Set up hyperparameters and model configuration"], "key_exports": ["run_all", "HistoneDataset", "BSampler"], "onboarding_reason": "Deprecated version - new developers should use deepchrome_doall.py instead."}, "old_scripts/[deprecated]_patch_v1.py": {"importance_score": 1, "summary": "Deprecated refactored version with modular functions for the DeepChrome pipeline.", "responsibilities": ["Parse input arguments and set parameters", "Check data dimensions and statistics", "Create modular dataset and dataloader functions", "Set hyperparameters with different configurations"], "key_exports": ["parse_in", "set_device", "check_dimensions", "HistoneDataset", "BSampler", "create_datasets_dataloaders", "set_hyperparams"], "onboarding_reason": "Deprecated code with incomplete implementation that new developers should skip."}, "old_scripts/[deprecated]_patch_v2.py": {"importance_score": 1, "summary": "Another deprecated version with device detection improvements but incomplete implementation.", "responsibilities": ["Improved device detection (CUDA/MPS/CPU)", "Modular function organization", "Data preprocessing and dimension checking", "Incomplete hyperparameter setup"], "key_exports": ["parse_in", "set_device", "check_dimensions", "HistoneDataset", "BSampler", "create_datasets_dataloaders", "set_hyperparams"], "onboarding_reason": "Incomplete deprecated code that should be ignored."}, "old_scripts/[deprecated]_patchnll_v0.py": {"importance_score": 1, "summary": "Deprecated version of DeepChrome script with incomplete implementation, appears to be testing NLL loss.", "responsibilities": ["Basic DeepChrome pipeline setup", "Data loading and preprocessing", "Model configuration setup", "Incomplete training implementation"], "key_exports": ["run_all", "HistoneDataset", "BSampler"], "onboarding_reason": "Incomplete deprecated code that new developers should skip."}, "optim.py": {"importance_score": 7, "summary": "This file implements neural network optimization functionality for genomic data analysis, including a 1D CNN architecture and training utilities. It handles data loading from CSV files, model training, and optimization for different cell types with configurable hyperparameters.", "responsibilities": ["Loads and preprocesses genomic training data from CSV files into windowed tensor format", "Defines a ConvNet class implementing a 1D CNN for binary classification on genomic sequences", "Manages hyperparameter configuration for different model specifications", "Handles model optimization and training loops with custom parameter groups"], "key_exports": ["set_device", "load_data", "set_hyperparams", "ConvNet", "opt"], "onboarding_reason": "New developers should read this to understand the core neural network architecture and training pipeline used for genomic data classification in this project."}}, "onboarding_path": [{"file": "README.md", "summary": "Main project documentation describing a DeepChrome model reimplementation for predicting gene expression from histone modifications.", "reason": "Start with project documentation to understand the overall goal, context, and architecture of the DeepChrome model reimplementation for predicting gene expression from histone modifications.", "importance_score": 8, "responsibilities": ["Document project structure and scripts", "Explain subfolder organization", "Provide overview of implemented models and analyses", "Guide users to results and benchmarks"], "key_exports": []}, {"file": "deepchrome_doall.py", "summary": "Main entry point script that runs complete DeepChrome model training, evaluation, and generates performance metrics.", "reason": "Read the main entry point to understand the complete workflow, model training pipeline, and evaluation process that ties everything together.", "importance_score": 9, "responsibilities": ["Orchestrate full model pipeline from training to evaluation", "Handle data loading and preprocessing with custom Dataset/BatchSampler", "Define and train ConvNet architecture", "Generate AUC, loss scores and save results"], "key_exports": ["run_all", "HistoneDataset", "BSampler"]}, {"file": "optim.py", "summary": "This file implements neural network optimization functionality for genomic data analysis, including a 1D CNN architecture and training utilities. It handles data loading from CSV files, model training, and optimization for different cell types with configurable hyperparameters.", "reason": "Study the core neural network implementation including the 1D CNN architecture, training utilities, and optimization logic that powers the DeepChrome model.", "importance_score": 7, "responsibilities": ["Loads and preprocesses genomic training data from CSV files into windowed tensor format", "Defines a ConvNet class implementing a 1D CNN for binary classification on genomic sequences", "Manages hyperparameter configuration for different model specifications", "Handles model optimization and training loops with custom parameter groups"], "key_exports": ["set_device", "load_data", "set_hyperparams", "ConvNet", "opt"]}, {"file": "ml_doall.py", "summary": "Baseline machine learning models script implementing Random Forest, SVM, and XGBoost for comparison with DeepChrome.", "reason": "Examine the baseline machine learning approaches (Random Forest, SVM, XGBoost) to understand alternative methods and comparison benchmarks.", "importance_score": 7, "responsibilities": ["Implement baseline ML models for performance comparison", "Use same data preprocessing pipeline as DeepChrome", "Train and evaluate traditional ML approaches", "Provide benchmarking against deep learning model"], "key_exports": ["run_all", "HistoneDataset", "BSampler"]}, {"file": "featmap.py", "summary": "Script for generating combinatorial interaction heatmaps and feature analysis from trained DeepChrome models.", "reason": "Finally, explore the analysis and visualization tools for generating feature interaction heatmaps and understanding model interpretability.", "importance_score": 7, "responsibilities": ["Extract convolutional layer features from trained models", "Generate feature map visualizations across cell types", "Load and process data for multiple cell types", "Create heatmap plots of feature distributions"], "key_exports": ["set_device", "load_data", "ConvNet", "extract_features", "plot_feat_map"]}]}